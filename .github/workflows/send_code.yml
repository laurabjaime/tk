name: Send Python Code to API

on:
  push:
    branches:
      - main  # Merge to main

jobs:
  send_code_to_api:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout the code
        uses: actions/checkout@v3

      - name: Debug - Check API Key
        run: |
          if [ -z "${{ secrets.API_KEY }}" ]; then
            echo "Error: API_KEY is missing from GitHub Secrets!"
            exit 1
          else
            echo "API_KEY is properly set!"
          fi

      - name: Read all Python files and store them as strings dynamically
        run: |
          echo "Searching for Python files..."

          # Lista todos os arquivos .py no repositório
          PYTHON_FILES=$(find . -maxdepth 1 -type f -name "*.py" | xargs -n 1 basename | tr '\n' ' ')

          # Se nenhum arquivo .py for encontrado, exibe um erro e interrompe o workflow
          if [ -z "$PYTHON_FILES" ]; then
            echo "ERROR: No Python files found!"
            exit 1
          fi

          echo "Found Python files: $PYTHON_FILES"

          # Armazena os nomes dos arquivos em uma variável de ambiente
          echo "PYTHON_FILES=${PYTHON_FILES}" >> $GITHUB_ENV

          # Loop para ler e armazenar o conteúdo de cada arquivo dinamicamente
          for file in $PYTHON_FILES; do
            FILE_NAME=$(basename "$file" .py | tr '[:lower:]' '[:upper:]')  # Remove .py e coloca em maiúsculas
            echo "📄 Processing file: $file → Stored as ${FILE_NAME}_CODE"

            FILE_CONTENT=$(awk '{printf "%s\\n", $0}' "$file" | paste -sd '' | sed 's/\\\\n/\\n/g' | sed 's/\n/\\n/g')

            # Se o arquivo estiver vazio, exibe um aviso mas continua o workflow
            if [[ -z "$FILE_CONTENT" ]]; then
              echo "WARNING: File $file is empty!"
              continue  # Continua para o próximo arquivo, sem interromper o workflow
            fi

            # Salva cada código no ambiente do GitHub Actions com um nome dinâmico
            echo "${FILE_NAME}_CODE=${FILE_CONTENT}" >> $GITHUB_ENV
          done

      - name: Send code to API dynamically
        env:
          API_KEY: ${{ secrets.API_KEY }}
          PYTHON_FILES: ${{ env.PYTHON_FILES }}
        run: |
          python - <<EOF
          import http.client
          import json
          import os

          # Configuração da API
          API_HOST = "eu-central-1.taktile-org.decide.taktile.com"
          ENDPOINT_LIST_FLOWS = "/run/api/v1/flows/list-decision-graphs/sandbox/decide"
          ENDPOINT_GET_GRAPH = "/run/api/v1/flows/get-decision-graph/sandbox/decide"
          ENDPOINT_UPDATE = "/run/api/v1/flows/patch-decision-graph/sandbox/decide"

          api_key = os.getenv("API_KEY")
          if not api_key:
              raise ValueError("❌ ERROR: API_KEY is empty!")

          headers = {
              "X-Api-Key": api_key,
              "accept": "application/json",
              "Content-Type": "application/json"
          }

          # Criar conexão com a API
          conn = http.client.HTTPSConnection(API_HOST)

          def flow_ids(org_name):
              """Obtém todos os flow_id da organização."""
              payload = json.dumps({
                  "data": {"organization_name": org_name},
                  "metadata": {"version": "v1.0", "entity_id": "string"},
                  "control": {"execution_mode": "sync"}
              })
              conn.request("POST", ENDPOINT_LIST_FLOWS, payload, headers)
              res = conn.getresponse()
              data = res.read()
              response_json = json.loads(data.decode("utf-8"))
              list_decision_flows=dict(response_json)
              flow_ids =[]
              for i in range(len(list_decision_flows['data']['flows'])):
                  flow_ids.append(list_decision_flows['data']['flows'][i]['flow_id'])
              return flow_ids

          def node_ids(org_name):
              """Obtém todos os node_id dos code_nodes de cada flow."""
              flows = flow_ids(org_name)
              ans = {}
              for flow_id in flows:
                  payload = json.dumps({
                      "data": {"flow_id": flow_id},
                      "metadata": {"version": "v1.0", "entity_id": "string"},
                      "control": {"execution_mode": "sync"}
                  })
                  conn.request("POST", ENDPOINT_GET_GRAPH, payload, headers)
                  res = conn.getresponse()
                  data = res.read()
                  response_json = json.loads(data.decode("utf-8"))
                  get_decision_flows=dict(response_json)
                  for i in range(len(get_decision_flows['data']['graph'])):
                      if get_decision_flows['data']['graph'][i]['node_type']=='code_node':
                          node_id = get_decision_flows['data']['graph'][i]['node_id']
                          if get_decision_flows['data']['graph'][i]['node_name'].lower() in ans:
                              ans[get_decision_flows['data']['graph'][i]['node_name'].lower()].append((flow_id,node_id))
                          else:
                              ans[get_decision_flows['data']['graph'][i]['node_name'].lower()] = [(flow_id,node_id)]

              return ans

          # Organização usada (pode ser parametrizado se necessário)
          ORGANIZATION_NAME = "NB36"
          
          # Node codes available
          nodes_available = node_ids(ORGANIZATION_NAME)

          # Lista de arquivos detectados
          python_files = os.getenv("PYTHON_FILES", "").split()
          if not python_files:
              raise ValueError("❌ ERROR: No Python files found!")

          print(f"✅ Found Python files: {python_files}")

          # Obter o mapeamento nome -> flow_id, node_id
          name_to_id_mapping = get_name_to_id_mapping(ORGANIZATION_NAME)
          print(f"📌 Mapping: {name_to_id_mapping}")

          # Enviar cada arquivo automaticamente
          for file_name in python_files:
              name = f"{file_name.replace('.py', '').lower()}"
              env_var = f"{file_name.replace('.py', '').upper()}_CODE"
              src_code = os.getenv(env_var)
              aux = nodes_available[name]
              for i in range(len(aux)):
                  flow_id = aux[i][0]
                  node_id = aux[i][1]

                  # Criar payload dinâmico
                  payload = json.dumps({
                      "data": {
                          "flow_id": flow_id,
                          "node_id": node_id,
                          "src_code": src_code
                      },
                      "metadata": {
                          "version": "v1.0",
                          "entity_id": "string"
                      },
                      "control": {
                          "execution_mode": "sync"
                      }
                  })
    
                  print(f"🚀 Sending {file_name} (flow_id: {flow_id}, node_id: {node_id}) to API...")
                  conn.request("POST", ENDPOINT_UPDATE, payload, headers)
                  res = conn.getresponse()
                  print(f"✅ {file_name} response:", res.status, res.read().decode("utf-8"))

          print("🎯 All files processed!")
          EOF


